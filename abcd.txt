// Function to clean hyphens from specific date fields in a JSON string
void CleanDatesInJson(const char *inputJson, char *outputJson, const char *dateKeys[], int numKeys) {
    const char *src = inputJson;
    char *dst = outputJson;
    int inQuotes = 0;
    int foundDateKey = 0;

    while (*src != '\0') {
        // Detect matching date key
        for (int i = 0; i < numKeys; i++) {
            size_t keyLen = strlen(dateKeys[i]);

            if (!inQuotes && strncmp(src, dateKeys[i], keyLen) == 0 && src[keyLen] == '"') {
                foundDateKey = 1;
                break;
            }
        }

        if (*src == '"') {
            inQuotes = !inQuotes;
            *dst++ = *src++;
        }
        else if (inQuotes && foundDateKey && *src == '-') {
            *dst++ = ' ';
            src++;
        }
        else {
            *dst++ = *src++;

            if (*(src - 1) == ',' || *(src - 1) == '}') {
                foundDateKey = 0; // Reset flag at end of value
            }
        }
    }

    *dst = '\0'; // Null-terminate the output string
}


======================

char rawJson[10000];
char cleanedJson[10000];

const char *dateKeys[] = {
    "ReceivedMerchantDate",
    "CardHolderDate",
    "MerchantShipDate"
};

// Capture JSON response
web_reg_save_param("FullJson",
    "LB=",
    "RB=",
    "Search=Body",
    LAST);

web_custom_request("GetData",
    "URL=http://example.com/api/get",
    "Method=GET",
    LAST);

// Clean dates
strcpy(rawJson, lr_eval_string("{FullJson}"));
CleanDatesInJson(rawJson, cleanedJson, dateKeys, sizeof(dateKeys)/sizeof(dateKeys[0]));

// Use cleaned JSON
web_custom_request("PostData",
    "URL=http://example.com/api/post",
    "Method=POST",
    "BodyBinary={cleanedJson}",
    LAST);

=============================


#ifndef CLEAN_JSON_H
#define CLEAN_JSON_H

#include <string.h>
#include <stdio.h>

// Replaces hyphens with spaces in values of specified date keys in a JSON string
void CleanDatesInJson(const char *inputJson, char *outputJson, const char *dateKeys[], int numKeys) {
    const char *src = inputJson;
    char *dst = outputJson;
    int inQuotes = 0;
    int foundDateKey = 0;

    while (*src != '\0') {
        // Detect matching date key
        for (int i = 0; i < numKeys; i++) {
            size_t keyLen = strlen(dateKeys[i]);

            // Only check for keys outside of quotes to avoid false positives
            if (!inQuotes && strncmp(src, dateKeys[i], keyLen) == 0 && src[keyLen] == '"') {
                foundDateKey = 1;
                break;
            }
        }

        // Toggle quote tracking
        if (*src == '"') {
            inQuotes = !inQuotes;
            *dst++ = *src++;
        }
        // Replace hyphen inside quoted value after key match
        else if (inQuotes && foundDateKey && *src == '-') {
            *dst++ = ' ';
            src++;
        }
        else {
            *dst++ = *src++;

            // If value segment ends, reset the date key flag
            if (*(src - 1) == ',' || *(src - 1) == '}') {
                foundDateKey = 0;
            }
        }
    }

    *dst = '\0'; // Null-terminate output
}

#endif // CLEAN_JSON_H



char rawJson[10000];
char cleanedJson[10000];

// Step 1: Save full JSON response
web_reg_save_param("FullJson",
    "LB=",
    "RB=",
    "Search=Body",
    LAST);

web_custom_request("GetTransactions",
    "URL=http://example.com/api/transactions",
    "Method=GET",
    LAST);

// Step 2: Evaluate and clean JSON
strcpy(rawJson, lr_eval_string("{FullJson}"));

// Define keys to clean
const char *dateKeys[] = {
    "ReceivedMerchantDate",
    "CardHolderDate",
    "MerchantShipDate"
};

// Call reusable function
CleanDatesInJson(rawJson, cleanedJson, dateKeys, sizeof(dateKeys)/sizeof(dateKeys[0]));

// Optional: Log cleaned output
lr_output_message("Cleaned JSON:\n%s", cleanedJson);

// Step 3: Use cleaned JSON as body in next request
web_custom_request("PostCleanedJson",
    "URL=http://example.com/api/nextstep",
    "Method=POST",
    "BodyBinary={cleanedJson}",
    LAST);



=================





char* str_replace(const char* original, char old_char, char new_char) {
    static char buffer[8192]; // Adjust size as needed
    int i;

    for (i = 0; original[i] != '\0' && i < sizeof(buffer) - 1; i++) {
        buffer[i] = (original[i] == old_char) ? new_char : original[i];
    }

    buffer[i] = '\0';
    return buffer;
}


char* original_json = lr_eval_string("{JsonParam}");
char* modified_json = str_replace(original_json, '-', '_');

lr_save_string(modified_json, "ModifiedJson");
lr_output_message("Modified JSON: %s", lr_eval_string("{ModifiedJson}"));


=================

import requests
import csv
import xml.etree.ElementTree as ET
from datetime import datetime
import sys

NAMESPACES = {
    'soap-env': 'http://schemas.xmlsoap.org/soap/envelope/',
    'ns0': 'http://example.com/ns'
}

API_URL = "https://your-api-endpoint.com/soap"

def parse_date(date_str):
    try:
        return datetime.strptime(date_str, '%Y-%m-%d')
    except:
        return datetime.min

def main(input_csv, output_file):
    # Prepare output file with header
    with open(output_file, 'w', newline='') as out_file:
        writer = csv.writer(out_file)
        writer.writerow(['applicationdesc', 'AcctNumber', 'relationship', 'AssociatedAcct', 'cardsratus',
                         'EffectiveDate', 'ExpiryDate', 'Address', 'Validity'])

    # Read input accounts
    with open(input_csv, newline='') as csvfile:
        reader = csv.DictReader(csvfile)
        for row in reader:
            acct_num = row['account_number'].strip()

            # Prepare SOAP request
            payload = f"""
            <soap-env:Envelope xmlns:soap-env="http://schemas.xmlsoap.org/soap/envelope/">
              <soap-env:Body>
                <ns0:GetAccountDetails xmlns:ns0="http://example.com/ns">
                  <ns0:AccountNumber>{acct_num}</ns0:AccountNumber>
                </ns0:GetAccountDetails>
              </soap-env:Body>
            </soap-env:Envelope>
            """

            try:
                response = requests.post(API_URL, data=payload, headers={'Content-Type': 'text/xml'})
                response.raise_for_status()
                root = ET.fromstring(response.text)

                # Group by (AcctNumber, AssociatedAcct)
                unique_debit_cards = {}

                for detail in root.findall('.//ns0:AcctDetail', NAMESPACES):
                    app_desc = detail.findtext('ns0:applicationdesc', '', NAMESPACES)
                    if 'debit' not in app_desc.lower():
                        continue

                    acct_number = detail.findtext('ns0:AcctNumber', '', NAMESPACES)
                    associated_acct = detail.findtext('ns0:ATMCardDetail/ns0:AssociatedAcct', '', NAMESPACES).strip()

                    if not associated_acct:
                        continue

                    expiry_date_str = detail.findtext('ns0:ExpiryDate', '', NAMESPACES)
                    expiry_date = parse_date(expiry_date_str)

                    key = (acct_number, associated_acct)
                    existing = unique_debit_cards.get(key)

                    if not existing or expiry_date > existing['parsed_expiry']:
                        unique_debit_cards[key] = {
                            'applicationdesc': 'DEBIT CARD',
                            'AcctNumber': acct_number,
                            'relationship': detail.findtext('ns0:relationship', '', NAMESPACES),
                            'AssociatedAcct': associated_acct,
                            'cardsratus': detail.findtext('ns0:ATMCardDetail/ns0:cardsratus', '', NAMESPACES),
                            'EffectiveDate': detail.findtext('ns0:EffectiveDate', '', NAMESPACES),
                            'ExpiryDate': expiry_date_str,
                            'Address': detail.findtext('ns0:Address', '', NAMESPACES),
                            'Validity': detail.findtext('ns0:Validity', '', NAMESPACES),
                            'parsed_expiry': expiry_date
                        }

                # Write unique records
                with open(output_file, 'a', newline='') as out_file:
                    writer = csv.writer(out_file)
                    for record in unique_debit_cards.values():
                        del record['parsed_expiry']
                        writer.writerow(record.values())

            except requests.RequestException as e:
                print(f"Error for account {acct_num}: {e}")

if __name__ == "__main__":
    if len(sys.argv) != 3:
        print("Usage: python script1.py <input_csv> <output_file>")
        sys.exit(1)

    input_csv = sys.argv[1]
    output_file = sys.argv[2]
    main(input_csv, output_file)



--
import subprocess

def run_script(script, input_file, output_file):
    print(f"Running {script} with input: {input_file}, output: {output_file}")
    subprocess.run(['python', script, input_file, output_file], check=True)

if __name__ == "__main__":
    run_script('script1.py', 'input_accounts.csv', 'output1.csv')
    run_script('script2.py', 'output1.csv', 'output2.csv')
    run_script('script3.py', 'output2.csv', 'output3.csv')
    print("Workflow complete.")


import random
import csv
from collections import defaultdict

def generate_combinations_without_count(
    input_file,
    output_file,
    sample_sizes=[2, 5, 10, 15],
    threshold=10,
    min_date="20250321",
    max_debits_per_account=3,
    samples_per_row=2
):
    # Track debit cards per account to limit output rows
    account_debit_tracker = defaultdict(set)

    with open(input_file, 'r') as infile, open(output_file, 'w', newline='') as outfile:
        reader = csv.reader(infile, delimiter='\t')
        writer = csv.writer(outfile, delimiter='\t')
        writer.writerow(['account', 'debit', 'dates', 'amounts'])  # header

        for row in reader:
            if len(row) != 5:
                continue  # skip malformed rows

            account, debit, dates_str, amts_str, _ = row
            dates = dates_str.split(',')
            amts = amts_str.split(',')

            if len(dates) != len(amts):
                continue  # skip if mismatch

            # Filter by min_date
            filtered = [(d, a) for d, a in zip(dates, amts) if d > min_date]
            count = len(filtered)

            if count <= 1:
                continue  # skip too small

            # Enforce max debit cards per account
            if debit not in account_debit_tracker[account]:
                if len(account_debit_tracker[account]) >= max_debits_per_account:
                    continue
                account_debit_tracker[account].add(debit)

            if count <= threshold:
                # Output full filtered row as is
                sample_dates = ','.join(d for d, _ in filtered)
                sample_amts = ','.join(a for _, a in filtered)
                writer.writerow([account, debit, sample_dates, sample_amts])
            else:
                # For counts > threshold: generate samples for each bucket <= count
                valid_buckets = [b for b in sorted(sample_sizes) if b <= count]
                for bucket in valid_buckets:
                    for _ in range(samples_per_row):
                        sample = random.sample(filtered, bucket)
                        sample_dates = ','.join(x[0] for x in sample)
                        sample_amts = ','.join(x[1] for x in sample)
                        writer.writerow([account, debit, sample_dates, sample_amts])



generate_combinations_without_count(
    input_file='input.tsv',
    output_file='output.tsv',
    sample_sizes=[2, 5, 10, 15],
    threshold=10,
    min_date="20250321",
    max_debits_per_account=3,
    samples_per_row=2
)



=====================




import random
import csv
from collections import defaultdict

def get_bucket(count, buckets):
    """Return the largest bucket that is <= count."""
    valid = [b for b in sorted(buckets) if b <= count]
    return valid[-1] if valid else None

def generate_combinations_without_count(
    input_file,
    output_file,
    sample_sizes=[2, 5, 10, 15],
    min_date="20250321",
    max_debits_per_account=3,
    samples_per_row=3
):
    # Track unique debit cards used per account
    account_debit_tracker = defaultdict(set)

    with open(input_file, 'r') as infile, open(output_file, 'w', newline='') as outfile:
        reader = csv.reader(infile, delimiter='\t')
        writer = csv.writer(outfile, delimiter='\t')

        # Optional header
        writer.writerow(['account', 'debit', 'dates', 'amounts'])

        for row in reader:
            if len(row) != 5:
                continue  # Skip malformed rows

            account, debit, dates_str, amts_str, _ = row  # We ignore 'codes' column

            dates = dates_str.split(',')
            amts = amts_str.split(',')

            if len(dates) != len(amts):
                continue  # Mismatched lengths

            # Filter based on date threshold
            filtered = [(d, a) for d, a in zip(dates, amts) if d > min_date]
            count = len(filtered)

            if count <= 1:
                continue  # Skip if not enough data after filtering

            # Limit how many debit cards are used per account
            if debit not in account_debit_tracker[account]:
                if len(account_debit_tracker[account]) >= max_debits_per_account:
                    continue  # Too many debit cards already used for this account
                account_debit_tracker[account].add(debit)

            bucket = get_bucket(count, sample_sizes)
            if not bucket:
                continue  # No valid bucket size found

            # Generate multiple samples of the same bucket size
            for _ in range(samples_per_row):
                sample = random.sample(filtered, bucket)
                sample_dates = ','.join([x[0] for x in sample])
                sample_amts = ','.join([x[1] for x in sample])
                writer.writerow([account, debit, sample_dates, sample_amts])



generate_combinations_without_count(
    input_file='input.tsv',
    output_file='output.tsv',
    sample_sizes=[2, 5, 10, 15],
    min_date="20250321",
    max_debits_per_account=3,
    samples_per_row=3
)


-------------------------


import csv
import random
from collections import defaultdict

def get_bucket(count, buckets):
    """
    Return the largest bucket from the list that is <= count.
    """
    valid_buckets = [b for b in sorted(buckets) if b <= count]
    return valid_buckets[-1] if valid_buckets else None

def generate_multiple_combinations_per_row(
    input_file,
    output_file,
    buckets=[2, 5, 10, 15],
    samples_per_row=3,
    max_debits_per_account=3  # NEW: Limit number of debit cards per account
):
    # Track how many unique debit cards we've used per account
    account_debit_counter = defaultdict(set)

    with open(input_file, 'r') as infile, open(output_file, 'w', newline='') as outfile:
        reader = csv.reader(infile, delimiter='\t')
        writer = csv.writer(outfile, delimiter='\t')

        # Write header
        writer.writerow(['account', 'debit', 'dates', 'amounts'])

        for row in reader:
            if len(row) < 4:
                continue  # Skip malformed rows

            account, debit, dates_str, amts_str = row[:4]
            dates = dates_str.split(',')
            amts = amts_str.split(',')
            count = len(dates)

            # Skip if invalid row
            if count != len(amts) or count <= 1:
                continue

            # Enforce unique debit cards per account
            if debit not in account_debit_counter[account]:
                if len(account_debit_counter[account]) >= max_debits_per_account:
                    continue  # Already reached max debit cards for this account
                account_debit_counter[account].add(debit)

            # Determine sampling bucket
            bucket = get_bucket(count, buckets)
            if bucket is None:
                continue

            # Pair date and amount
            combos = list(zip(dates, amts))

            # Generate N random samples
            for _ in range(samples_per_row):
                sample = random.sample(combos, bucket)
                sample_dates = ','.join([x[0] for x in sample])
                sample_amts = ','.join([x[1] for x in sample])
                writer.writerow([account, debit, sample_dates, sample_amts])
generate_multiple_combinations_per_row(
    input_file='input.tsv',
    output_file='output.tsv',
    buckets=[2, 5, 10, 15],
    samples_per_row=3,
    max_debits_per_account=3  # Only allow up to 3 debit cards per account
)

=====================

#DATE FILTER
import csv
import random
from collections import defaultdict

def get_bucket(count, buckets):
    """Return the largest bucket from the list that is <= count."""
    valid_buckets = [b for b in sorted(buckets) if b <= count]
    return valid_buckets[-1] if valid_buckets else None

def generate_multiple_combinations_per_row(
    input_file,
    output_file,
    buckets=[2, 5, 10, 15],
    samples_per_row=3,
    max_debits_per_account=3,
    min_date_threshold="20250101"  # NEW: Only allow dates greater than this
):
    account_debit_counter = defaultdict(set)

    with open(input_file, 'r') as infile, open(output_file, 'w', newline='') as outfile:
        reader = csv.reader(infile, delimiter='\t')
        writer = csv.writer(outfile, delimiter='\t')

        writer.writerow(['account', 'debit', 'dates', 'amounts'])  # header

        for row in reader:
            if len(row) < 4:
                continue  # malformed row

            account, debit, dates_str, amts_str = row[:4]
            dates = dates_str.split(',')
            amts = amts_str.split(',')

            if len(dates) != len(amts):
                continue

            # Filter (date, amount) pairs based on min_date_threshold
            filtered = [(d, a) for d, a in zip(dates, amts) if d > min_date_threshold]

            # Skip rows with less than 2 valid pairs
            if len(filtered) < 2:
                continue

            # Enforce max debits per account
            if debit not in account_debit_counter[account]:
                if len(account_debit_counter[account]) >= max_debits_per_account:
                    continue
                account_debit_counter[account].add(debit)

            bucket = get_bucket(len(filtered), buckets)
            if bucket is None:
                continue

            for _ in range(samples_per_row):
                sample = random.sample(filtered, bucket)
                sample_dates = ','.join([x[0] for x in sample])
                sample_amts = ','.join([x[1] for x in sample])
                writer.writerow([account, debit, sample_dates, sample_amts])


generate_multiple_combinations_per_row(
    input_file='input.tsv',
    output_file='output.tsv',
    buckets=[2, 5, 10, 15],
    samples_per_row=3,
    max_debits_per_account=3,
    min_date_threshold="20250321"  # Only include transactions after this date
)



import csv  # For reading and writing TSV files
import random  # For randomly sampling combinations

def get_bucket(count, buckets):
    """
    Return the largest bucket from the list that is less than or equal to the count.
    E.g., if count = 7 and buckets = [2, 5, 10], it returns 5.
    """
    valid_buckets = [b for b in sorted(buckets) if b <= count]
    return valid_buckets[-1] if valid_buckets else None

def generate_multiple_combinations_per_row(input_file, output_file, buckets=[2, 5, 10, 15], samples_per_row=3):
    # Open input TSV file for reading, and output TSV file for writing
    with open(input_file, 'r') as infile, open(output_file, 'w', newline='') as outfile:
        reader = csv.reader(infile, delimiter='\t')  # Create TSV reader
        writer = csv.writer(outfile, delimiter='\t')  # Create TSV writer

        # Write header row to the output file
        writer.writerow(['account', 'debit', 'dates', 'amounts'])

        # Process each line in the input file
        for row in reader:
            if len(row) < 4:
                continue  # Skip if the row doesn't have enough columns

            # Extract fields from the input row
            account, debit, dates_str, amts_str = row[:4]

            # Split the dates and amounts into lists
            dates = dates_str.split(',')
            amts = amts_str.split(',')

            count = len(dates)  # Determine how many combinations exist

            # Skip row if counts don't match or there's only one combination
            if count != len(amts) or count <= 1:
                continue

            # Determine appropriate bucket size based on available count
            bucket = get_bucket(count, buckets)
            if bucket is None:
                continue  # Skip if no valid bucket found

            # Zip dates and amounts together to form a list of (date, amount) pairs
            combos = list(zip(dates, amts))

            # Generate multiple random samples per row
            for _ in range(samples_per_row):
                sample = random.sample(combos, bucket)  # Pick 'bucket'-sized random sample
                sample_dates = ','.join([x[0] for x in sample])  # Extract dates from the sample
                sample_amts = ','.join([x[1] for x in sample])   # Extract amounts from the sample

                # Write the sampled data to the output file
                writer.writerow([account, debit, sample_dates, sample_amts])



#================

import csv
import random

def get_bucket(count, buckets):
    """
    Return the largest bucket that is <= count.
    """
    valid_buckets = [b for b in sorted(buckets) if b <= count]
    return valid_buckets[-1] if valid_buckets else None

def generate_bucketed_combinations(input_file, output_file, buckets=[2, 5, 10, 15]):
    with open(input_file, 'r') as infile, open(output_file, 'w', newline='') as outfile:
        reader = csv.reader(infile, delimiter='\t')
        writer = csv.writer(outfile, delimiter='\t')

        for row in reader:
            if len(row) != 5:
                continue  # Skip malformed rows

            account, debit, dates_str, amts_str, codes_str = row
            dates = dates_str.split(',')
            amts = amts_str.split(',')
            codes = codes_str.split(',')

            count = len(dates)

            # Sanity check
            if count != len(amts) or count != len(codes):
                continue  # Skip inconsistent rows

            if count <= 1:
                continue  # Skip if only one combination

            bucket = get_bucket(count, buckets)
            if bucket is None:
                continue  # No matching bucket

            sample = random.sample(list(zip(dates, amts, codes)), bucket)
            sample_dates = ','.join([x[0] for x in sample])
            sample_amts = ','.join([x[1] for x in sample])
            sample_codes = ','.join([x[2] for x in sample])

            writer.writerow([account, debit, sample_dates, sample_amts, sample_codes])


import random
import csv

def generate_selective_combinations(input_file, output_file, sample_sizes=[2, 5, 10, 15], threshold=10):
    with open(input_file, 'r') as infile, open(output_file, 'w', newline='') as outfile:
        reader = csv.reader(infile, delimiter='\t')
        writer = csv.writer(outfile, delimiter='\t')

        for row in reader:
            account, debit, dates_str, amts_str, count_str, codes_str = row
            count = int(count_str)
            dates = dates_str.split(',')
            amts = amts_str.split(',')
            codes = codes_str.split(',')

            combo_list = list(zip(dates, amts, codes))
            total = len(combo_list)

            if count > threshold:
                for size in sample_sizes:
                    if size > total:
                        continue  # skip if not enough data
                    sample = random.sample(combo_list, size)
                    sample_dates = ','.join([x[0] for x in sample])
                    sample_amts = ','.join([x[1] for x in sample])
                    sample_codes = ','.join([x[2] for x in sample])
                    writer.writerow([account, debit, sample_dates, sample_amts, size, sample_codes])
            else:
                # Write original row unchanged
                writer.writerow(row)

# Example usage
generate_selective_combinations('input.tsv', 'output.tsv', sample_sizes=[2, 5, 10, 15], threshold=10)



import random
import csv

def generate_combinations_without_count(input_file, output_file, sample_sizes=[2, 5, 10, 15], threshold=10):
    with open(input_file, 'r') as infile, open(output_file, 'w', newline='') as outfile:
        reader = csv.reader(infile, delimiter='\t')
        writer = csv.writer(outfile, delimiter='\t')

        for row in reader:
            if len(row) != 5:
                continue  # Skip malformed rows

            account, debit, dates_str, amts_str, codes_str = row
            dates = dates_str.split(',')
            amts = amts_str.split(',')
            codes = codes_str.split(',')

            combo_list = list(zip(dates, amts, codes))
            total = len(combo_list)

            if total > threshold:
                for size in sample_sizes:
                    if size > total:
                        continue
                    sample = random.sample(combo_list, size)
                    sample_dates = ','.join([x[0] for x in sample])
                    sample_amts = ','.join([x[1] for x in sample])
                    sample_codes = ','.join([x[2] for x in sample])
                    writer.writerow([account, debit, sample_dates, sample_amts, sample_codes])
            else:
                # Write the original row as-is
                writer.writerow(row)

# Example usage
generate_combinations_without_count('input.tsv', 'output.tsv', sample_sizes=[2, 5, 10, 15], threshold=10)

